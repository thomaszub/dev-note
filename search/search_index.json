{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dev Note Notes about various topics in software development.","title":"Introduction"},{"location":"#dev-note","text":"Notes about various topics in software development.","title":"Dev Note"},{"location":"agile_methods/","text":"Agile methods This note contains informations about agile methods.","title":"Agile methods"},{"location":"agile_methods/#agile-methods","text":"This note contains informations about agile methods.","title":"Agile methods"},{"location":"agile_methods/invest/","text":"INVEST The INVEST mnemonic stands for six characteristics for a work item. I ndependent N egotiable V aluable E stimable S mall T estable","title":"INVEST"},{"location":"agile_methods/invest/#invest","text":"The INVEST mnemonic stands for six characteristics for a work item. I ndependent N egotiable V aluable E stimable S mall T estable","title":"INVEST"},{"location":"design_pattern/","text":"Design pattern This note contains informations about design patterns, mainly from the book \"Design Patterns\" from the Gang of Four.","title":"Design pattern"},{"location":"design_pattern/#design-pattern","text":"This note contains informations about design patterns, mainly from the book \"Design Patterns\" from the Gang of Four.","title":"Design pattern"},{"location":"design_pattern/behavioral/","text":"Behavioral Behavioral design patterns describe the communications between objects in a system.","title":"Behavioral"},{"location":"design_pattern/behavioral/#behavioral","text":"Behavioral design patterns describe the communications between objects in a system.","title":"Behavioral"},{"location":"design_pattern/behavioral/observer/","text":"Observer The observer is publish-subscribe-pattern typically found in event-driven systems. The observable maintains a list of observers and notifies them on events like changes in state. sequenceDiagram participant Observable participant Observer1 participant Observer2 Observer1->>Observable: register Observer2->>Observable: register Note over Observable: Event occurs in Observable Observable->>Observer1: update(Event) Observable->>Observer2: update(Event) Weak reference In the case that the observable holds a strong reference to an observer, the observer would not be cleaned up by e.g garbage collection or reference counting if its life cycle ends. This can be solved by weak references.","title":"Observer"},{"location":"design_pattern/behavioral/observer/#observer","text":"The observer is publish-subscribe-pattern typically found in event-driven systems. The observable maintains a list of observers and notifies them on events like changes in state. sequenceDiagram participant Observable participant Observer1 participant Observer2 Observer1->>Observable: register Observer2->>Observable: register Note over Observable: Event occurs in Observable Observable->>Observer1: update(Event) Observable->>Observer2: update(Event)","title":"Observer"},{"location":"design_pattern/behavioral/observer/#weak-reference","text":"In the case that the observable holds a strong reference to an observer, the observer would not be cleaned up by e.g garbage collection or reference counting if its life cycle ends. This can be solved by weak references.","title":"Weak reference"},{"location":"design_pattern/behavioral/visitor/","text":"Visitor The visitor pattern separates algorithms from the object structures they work on. If supported, this can be done by double dispatch or reflection.","title":"Visitor"},{"location":"design_pattern/behavioral/visitor/#visitor","text":"The visitor pattern separates algorithms from the object structures they work on. If supported, this can be done by double dispatch or reflection.","title":"Visitor"},{"location":"frameworks_and_tools/","text":"Frameworks and tools This note contains informations about frameworks and tools.","title":"Frameworks and tools"},{"location":"frameworks_and_tools/#frameworks-and-tools","text":"This note contains informations about frameworks and tools.","title":"Frameworks and tools"},{"location":"frameworks_and_tools/peotry/","text":"Poetry Poetry is a Python tool for package and dependency management. Configuration To create the virtual enviroments in the project and not in a global directory, the following command can be used: poetry config virtualenvs.in-project true","title":"Poetry"},{"location":"frameworks_and_tools/peotry/#poetry","text":"Poetry is a Python tool for package and dependency management.","title":"Poetry"},{"location":"frameworks_and_tools/peotry/#configuration","text":"To create the virtual enviroments in the project and not in a global directory, the following command can be used: poetry config virtualenvs.in-project true","title":"Configuration"},{"location":"machine_learning/","text":"Machine learning This note is about machine learning.","title":"Machine learning"},{"location":"machine_learning/#machine-learning","text":"This note is about machine learning.","title":"Machine learning"},{"location":"machine_learning/activation_functions/","text":"Activation functions Sigmoid / Logistic The Sigmoid activation function is defined by \\[ \\sigma(x) = \\frac{1}{1 + e^{-x}} \\] As the Sigmoid function has the bounds [0, 1], it is suited for multi-label classification as the element results can be trained as probabilities for a certain label to be true or not. Softmax The Softmax activation function is defined by \\[ \\sigma_j(x) = \\frac{e^{x_j}}{\\sum_j{e^{x_j}}} \\] In comparison to most activation functions, the sum of all element-wise results is constrained, precisely speaking: \\[ \\sum_j \\sigma_j(x) = 1 \\] Therefore the Softmax function is suited for multi-class classification as the element results can be trained as probabilities for a certain class in one category to be true or not.","title":"Activation functions"},{"location":"machine_learning/activation_functions/#activation-functions","text":"","title":"Activation functions"},{"location":"machine_learning/activation_functions/#sigmoid-logistic","text":"The Sigmoid activation function is defined by \\[ \\sigma(x) = \\frac{1}{1 + e^{-x}} \\] As the Sigmoid function has the bounds [0, 1], it is suited for multi-label classification as the element results can be trained as probabilities for a certain label to be true or not.","title":"Sigmoid / Logistic"},{"location":"machine_learning/activation_functions/#softmax","text":"The Softmax activation function is defined by \\[ \\sigma_j(x) = \\frac{e^{x_j}}{\\sum_j{e^{x_j}}} \\] In comparison to most activation functions, the sum of all element-wise results is constrained, precisely speaking: \\[ \\sum_j \\sigma_j(x) = 1 \\] Therefore the Softmax function is suited for multi-class classification as the element results can be trained as probabilities for a certain class in one category to be true or not.","title":"Softmax"},{"location":"machine_learning/data_preprocessing/","text":"Data preprocessing Label encoder Python: from sklearn.preprocessing import LabelEncoder One hot encoder Python: from sklearn.preprocessing import OneHotEncoder Column transformer Scikit-learn contains a class for applying multiple transformations to a dataset including dropping columns: Python: from sklearn.compose import ColumnTransformer Note: Does currently not work with a LabelEncoder.","title":"Data preprocessing"},{"location":"machine_learning/data_preprocessing/#data-preprocessing","text":"","title":"Data preprocessing"},{"location":"machine_learning/data_preprocessing/#label-encoder","text":"Python: from sklearn.preprocessing import LabelEncoder","title":"Label encoder"},{"location":"machine_learning/data_preprocessing/#one-hot-encoder","text":"Python: from sklearn.preprocessing import OneHotEncoder","title":"One hot encoder"},{"location":"machine_learning/data_preprocessing/#column-transformer","text":"Scikit-learn contains a class for applying multiple transformations to a dataset including dropping columns: Python: from sklearn.compose import ColumnTransformer Note: Does currently not work with a LabelEncoder.","title":"Column transformer"},{"location":"machine_learning/feature_scaling/","text":"Feature scaling Feature scaling is a data preprocessing step to ease training of neural networks by reducing the numeric scale of different features to a uniform scale. Standardisation Standardisation transforms the feature distribution of data to zero mean and unit variance: \\[ z = \\frac{x - \\operatorname{mean}(x)}{\\operatorname{std}(x)} \\] Python: from sklearn.preprocessing import StandardScaler Normalisation Normalisation transforms the feature distribution to the interval \\([0,1]\\) : \\[ z = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} \\] Python: from sklearn.preprocessing import MinMaxScaler","title":"Feature scaling"},{"location":"machine_learning/feature_scaling/#feature-scaling","text":"Feature scaling is a data preprocessing step to ease training of neural networks by reducing the numeric scale of different features to a uniform scale.","title":"Feature scaling"},{"location":"machine_learning/feature_scaling/#standardisation","text":"Standardisation transforms the feature distribution of data to zero mean and unit variance: \\[ z = \\frac{x - \\operatorname{mean}(x)}{\\operatorname{std}(x)} \\] Python: from sklearn.preprocessing import StandardScaler","title":"Standardisation"},{"location":"machine_learning/feature_scaling/#normalisation","text":"Normalisation transforms the feature distribution to the interval \\([0,1]\\) : \\[ z = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} \\] Python: from sklearn.preprocessing import MinMaxScaler","title":"Normalisation"},{"location":"machine_learning/artifical_neural_networks/","text":"Artificial neural networks This note is about artificial neural networks (ANN). These networks belong to supervised learning and are used in the analysis and prediction of classification and regression problems.","title":"Artifical neural networks"},{"location":"machine_learning/artifical_neural_networks/#artificial-neural-networks","text":"This note is about artificial neural networks (ANN). These networks belong to supervised learning and are used in the analysis and prediction of classification and regression problems.","title":"Artificial neural networks"},{"location":"machine_learning/convolutional_neural_networks/","text":"Convolutional neural networks This note is about convolutional neural networks (CNN). These networks belong to supervised learning and are used in the field of computer vision.","title":"Convolutional neural networks"},{"location":"machine_learning/convolutional_neural_networks/#convolutional-neural-networks","text":"This note is about convolutional neural networks (CNN). These networks belong to supervised learning and are used in the field of computer vision.","title":"Convolutional neural networks"},{"location":"machine_learning/recurrent_neural_networks/","text":"Recurrent neural networks This note is about recurrent neural networks (RNN). These networks belong to supervised learning and are used in the analysis and prediction of time series or series like data. There are three general types of RNNs describing the series relation in input and output: Type Example One to many Sentence describing image Many to one Sentiment analysis Many to many Sentence translation Vanishing / exploding gradient problem RNNs can inhibit the vanishing / exploding gradient problem. One popular solution ist the use of long short-term memory (LSTM) nodes. Further readings: Diplomarbeit Josef Hochreiter, 1991: http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf","title":"Recurrent neural networks"},{"location":"machine_learning/recurrent_neural_networks/#recurrent-neural-networks","text":"This note is about recurrent neural networks (RNN). These networks belong to supervised learning and are used in the analysis and prediction of time series or series like data. There are three general types of RNNs describing the series relation in input and output: Type Example One to many Sentence describing image Many to one Sentiment analysis Many to many Sentence translation","title":"Recurrent neural networks"},{"location":"machine_learning/recurrent_neural_networks/#vanishing-exploding-gradient-problem","text":"RNNs can inhibit the vanishing / exploding gradient problem. One popular solution ist the use of long short-term memory (LSTM) nodes.","title":"Vanishing / exploding gradient problem"},{"location":"machine_learning/recurrent_neural_networks/#further-readings","text":"Diplomarbeit Josef Hochreiter, 1991: http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf","title":"Further readings:"},{"location":"machine_learning/recurrent_neural_networks/ltsm/","text":"Long short-term memory","title":"Long short-term memory"},{"location":"machine_learning/recurrent_neural_networks/ltsm/#long-short-term-memory","text":"","title":"Long short-term memory"},{"location":"microservices/","text":"Microservices","title":"Microservices"},{"location":"microservices/#microservices","text":"","title":"Microservices"},{"location":"microservices/service_interaction/","text":"Service interaction This note describes interaction procedures used in microservice architectures. Choreography In the choreography each service knows its role in a business process and therefore it needs to know all following services it has to call for the business process. sequenceDiagram participant Service1 participant Service2 participant Service3 Service1->>Service2: request Service1->>Service3: request Service3->>Service2: request Note : Response side suppressed for clarity. Orchestration In the orchestration a business process is executed by a central coordinator. The services theirself do not have to know the underlying business process and services involved in the business process. sequenceDiagram participant Coordinator participant Service1 participant Service2 participant Service3 Coordinator->>Service1: request Coordinator->>Service2: request Coordinator->>Service3: request Coordinator->>Service2: request Note : Response side suppressed for clarity.","title":"Service interaction"},{"location":"microservices/service_interaction/#service-interaction","text":"This note describes interaction procedures used in microservice architectures.","title":"Service interaction"},{"location":"microservices/service_interaction/#choreography","text":"In the choreography each service knows its role in a business process and therefore it needs to know all following services it has to call for the business process. sequenceDiagram participant Service1 participant Service2 participant Service3 Service1->>Service2: request Service1->>Service3: request Service3->>Service2: request Note : Response side suppressed for clarity.","title":"Choreography"},{"location":"microservices/service_interaction/#orchestration","text":"In the orchestration a business process is executed by a central coordinator. The services theirself do not have to know the underlying business process and services involved in the business process. sequenceDiagram participant Coordinator participant Service1 participant Service2 participant Service3 Coordinator->>Service1: request Coordinator->>Service2: request Coordinator->>Service3: request Coordinator->>Service2: request Note : Response side suppressed for clarity.","title":"Orchestration"}]}