{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dev Note Notes about various topics in software development.","title":"Introduction"},{"location":"#dev-note","text":"Notes about various topics in software development.","title":"Dev Note"},{"location":"agile_methods/","text":"Agile methods This note contains informations about agile methods.","title":"Agile methods"},{"location":"agile_methods/#agile-methods","text":"This note contains informations about agile methods.","title":"Agile methods"},{"location":"agile_methods/invest/","text":"INVEST The INVEST mnemonic stands for six characteristics for a work item. I ndependent N egotiable V aluable E stimable S mall T estable","title":"INVEST"},{"location":"agile_methods/invest/#invest","text":"The INVEST mnemonic stands for six characteristics for a work item. I ndependent N egotiable V aluable E stimable S mall T estable","title":"INVEST"},{"location":"agile_methods/metrics-flow/","text":"Flow metrics This note is about the metrics of work item flow. Basic flow metrics There are four basic flow metrics Work in Progress - Work items that are started but not finished Cycle time - Elapsed time between start and end of a work item Work item age - Elapsed time between start of a work item and the current time Throughput - Number of work items finished per unit of time Little's law Little's law states that the following relationship holds: \\[ \\operatorname{average cycle time} = \\frac{\\operatorname{average work in progress}}{\\operatorname{average throughput}} \\] Further readings: 4 Key Flow Metrics and how to use them in Scrum's events: https://www.scrum.org/resources/blog/4-key-flow-metrics-and-how-use-them-scrums-events","title":"Flow metrics"},{"location":"agile_methods/metrics-flow/#flow-metrics","text":"This note is about the metrics of work item flow.","title":"Flow metrics"},{"location":"agile_methods/metrics-flow/#basic-flow-metrics","text":"There are four basic flow metrics Work in Progress - Work items that are started but not finished Cycle time - Elapsed time between start and end of a work item Work item age - Elapsed time between start of a work item and the current time Throughput - Number of work items finished per unit of time","title":"Basic flow metrics"},{"location":"agile_methods/metrics-flow/#littles-law","text":"Little's law states that the following relationship holds: \\[ \\operatorname{average cycle time} = \\frac{\\operatorname{average work in progress}}{\\operatorname{average throughput}} \\]","title":"Little's law"},{"location":"agile_methods/metrics-flow/#further-readings","text":"4 Key Flow Metrics and how to use them in Scrum's events: https://www.scrum.org/resources/blog/4-key-flow-metrics-and-how-use-them-scrums-events","title":"Further readings:"},{"location":"agile_methods/scrum/","text":"Scrum This note is about the Scrum framework Three empircal pillars The three pillars are based on empiricism and lean thinking. Transparency Transparency reveals the state of the work and enables inspection to be of value. If the perceived state is intransparent, it will lead to a inprecise perceived state resulting in lower value and higher risk. Inspection The work has to be inspected frequently to be able to adjust accordingly in the case of deviations and problems. Inspection enables adaption. Adaption In the occurrence of deviations or problems in the process and work the team has to adapt fast to minimize further problems. To adapt fast, a team has to be self-managing. Five values The member of the Scrum team should act accordingly to the five values empowering their team work. Commitment Focus Openness Respect Courage Events Five events are practised in Scrum: Sprint Sprint Planning Daily Scrum Sprint Review Sprint Retrospective Artifacts Three artifacts represent value or work in Scrum and each is commited to one goal: Product Backlog -> Product Goal Spring Backlog -> Sprint Goal Increment -> Definition of Done Reference https://scrumguides.org/download.html","title":"Scrum"},{"location":"agile_methods/scrum/#scrum","text":"This note is about the Scrum framework","title":"Scrum"},{"location":"agile_methods/scrum/#three-empircal-pillars","text":"The three pillars are based on empiricism and lean thinking.","title":"Three empircal pillars"},{"location":"agile_methods/scrum/#transparency","text":"Transparency reveals the state of the work and enables inspection to be of value. If the perceived state is intransparent, it will lead to a inprecise perceived state resulting in lower value and higher risk.","title":"Transparency"},{"location":"agile_methods/scrum/#inspection","text":"The work has to be inspected frequently to be able to adjust accordingly in the case of deviations and problems. Inspection enables adaption.","title":"Inspection"},{"location":"agile_methods/scrum/#adaption","text":"In the occurrence of deviations or problems in the process and work the team has to adapt fast to minimize further problems. To adapt fast, a team has to be self-managing.","title":"Adaption"},{"location":"agile_methods/scrum/#five-values","text":"The member of the Scrum team should act accordingly to the five values empowering their team work. Commitment Focus Openness Respect Courage","title":"Five values"},{"location":"agile_methods/scrum/#events","text":"Five events are practised in Scrum: Sprint Sprint Planning Daily Scrum Sprint Review Sprint Retrospective","title":"Events"},{"location":"agile_methods/scrum/#artifacts","text":"Three artifacts represent value or work in Scrum and each is commited to one goal: Product Backlog -> Product Goal Spring Backlog -> Sprint Goal Increment -> Definition of Done","title":"Artifacts"},{"location":"agile_methods/scrum/#reference","text":"https://scrumguides.org/download.html","title":"Reference"},{"location":"architecture/","text":"Architecture This note contains informations about software architectures.","title":"Architecture"},{"location":"architecture/#architecture","text":"This note contains informations about software architectures.","title":"Architecture"},{"location":"architecture/entity_component_system/","text":"Entity-Component-System architecture The Entity-Component-System architecture is mainly used in game development to overcome the design problem of a domain with many entities with different but shared characteristics, named components, which can possibly change during runtime. In a naive design this would lead to a deep and complex inheritence structure or many different classes injecting the necessary components with a mechanism to handle the removal or addition of components. The Entity-Component-System architecture is mainly data-driven and can be seen as the implementation of an in-memory database. Entity The entity is an object of the domain, which can be recognised by a unique identifier. Typically the unique identifier is the only member of an entity class. Component A component represents a functional aspect of the domain, one or multiple instances of a component represent this aspect for a specific entity. The instances are connected with the entity by the unique identifier of the entity. System The system executes business logic on every entity using the needed components of the entity according to the executed command.","title":"Entity component system"},{"location":"architecture/entity_component_system/#entity-component-system-architecture","text":"The Entity-Component-System architecture is mainly used in game development to overcome the design problem of a domain with many entities with different but shared characteristics, named components, which can possibly change during runtime. In a naive design this would lead to a deep and complex inheritence structure or many different classes injecting the necessary components with a mechanism to handle the removal or addition of components. The Entity-Component-System architecture is mainly data-driven and can be seen as the implementation of an in-memory database.","title":"Entity-Component-System architecture"},{"location":"architecture/entity_component_system/#entity","text":"The entity is an object of the domain, which can be recognised by a unique identifier. Typically the unique identifier is the only member of an entity class.","title":"Entity"},{"location":"architecture/entity_component_system/#component","text":"A component represents a functional aspect of the domain, one or multiple instances of a component represent this aspect for a specific entity. The instances are connected with the entity by the unique identifier of the entity.","title":"Component"},{"location":"architecture/entity_component_system/#system","text":"The system executes business logic on every entity using the needed components of the entity according to the executed command.","title":"System"},{"location":"architecture/event_driven/","text":"Event-driven architecture Event notification Pro Decoupling sender and receiver Contra No statement of overall behavior Event-carried state transfer Pro Further decoupling Reduced load on sender Contra Replicated data, eventual consistency Event sourcing Pro TODO Contra TODO CQRS Pro TODO Contra TODO","title":"Event driven"},{"location":"architecture/event_driven/#event-driven-architecture","text":"","title":"Event-driven architecture"},{"location":"architecture/event_driven/#event-notification","text":"","title":"Event notification"},{"location":"architecture/event_driven/#pro","text":"Decoupling sender and receiver","title":"Pro"},{"location":"architecture/event_driven/#contra","text":"No statement of overall behavior","title":"Contra"},{"location":"architecture/event_driven/#event-carried-state-transfer","text":"","title":"Event-carried state transfer"},{"location":"architecture/event_driven/#pro_1","text":"Further decoupling Reduced load on sender","title":"Pro"},{"location":"architecture/event_driven/#contra_1","text":"Replicated data, eventual consistency","title":"Contra"},{"location":"architecture/event_driven/#event-sourcing","text":"","title":"Event sourcing"},{"location":"architecture/event_driven/#pro_2","text":"TODO","title":"Pro"},{"location":"architecture/event_driven/#contra_2","text":"TODO","title":"Contra"},{"location":"architecture/event_driven/#cqrs","text":"","title":"CQRS"},{"location":"architecture/event_driven/#pro_3","text":"TODO","title":"Pro"},{"location":"architecture/event_driven/#contra_3","text":"TODO","title":"Contra"},{"location":"concepts/","text":"Concepts This note contains informations about concepts like domain-driven design.","title":"Concepts"},{"location":"concepts/#concepts","text":"This note contains informations about concepts like domain-driven design.","title":"Concepts"},{"location":"concepts/big_data/","text":"Big data Big data can be commonly defined by the three Vs: volume, velocity and variety.","title":"Big data"},{"location":"concepts/big_data/#big-data","text":"Big data can be commonly defined by the three Vs: volume, velocity and variety.","title":"Big data"},{"location":"concepts/clean_code/","text":"Clean Code This note contains informations about clean code. Open Closed Principle Avoid switch statements, use polymorphism Command and query separation Function returning void has a side effect (command), function returning a value should have no side effects (query)","title":"Clean code"},{"location":"concepts/clean_code/#clean-code","text":"This note contains informations about clean code.","title":"Clean Code"},{"location":"concepts/clean_code/#open-closed-principle","text":"Avoid switch statements, use polymorphism","title":"Open Closed Principle"},{"location":"concepts/clean_code/#command-and-query-separation","text":"Function returning void has a side effect (command), function returning a value should have no side effects (query)","title":"Command and query separation"},{"location":"concepts/domain_driven_design/","text":"Domain-driven design This note contains informations about domain-driven design. Bounded context The bounded context is the context in which a model applies. It explicitly set boundaries to other bounded contexts. Example: Customer An example of different bounded contexts with a customer model is: Marketing -> Social interest, likes, needs Invoice -> Address, payment method Support -> Tickets All these three bounded contexts share the customer as a boundary. Aggregate \"Aggregate is synonymous with transactional consistency boundary. \u201c Vaughn Vernon. \u201eImplementing Domain-Driven Design.\u201c","title":"Domain driven design"},{"location":"concepts/domain_driven_design/#domain-driven-design","text":"This note contains informations about domain-driven design.","title":"Domain-driven design"},{"location":"concepts/domain_driven_design/#bounded-context","text":"The bounded context is the context in which a model applies. It explicitly set boundaries to other bounded contexts.","title":"Bounded context"},{"location":"concepts/domain_driven_design/#example-customer","text":"An example of different bounded contexts with a customer model is: Marketing -> Social interest, likes, needs Invoice -> Address, payment method Support -> Tickets All these three bounded contexts share the customer as a boundary.","title":"Example: Customer"},{"location":"concepts/domain_driven_design/#aggregate","text":"\"Aggregate is synonymous with transactional consistency boundary. \u201c Vaughn Vernon. \u201eImplementing Domain-Driven Design.\u201c","title":"Aggregate"},{"location":"concepts/domain_driven_design/entities/","text":"Entities Late vs early identity generation","title":"Entities"},{"location":"concepts/domain_driven_design/entities/#entities","text":"Late vs early identity generation","title":"Entities"},{"location":"design_pattern/","text":"Design pattern This note contains informations about design patterns, mainly from the book \"Design Patterns\" from the Gang of Four.","title":"Design pattern"},{"location":"design_pattern/#design-pattern","text":"This note contains informations about design patterns, mainly from the book \"Design Patterns\" from the Gang of Four.","title":"Design pattern"},{"location":"design_pattern/behavioral/","text":"Behavioral Behavioral design patterns describe the communications between objects in a system.","title":"Behavioral"},{"location":"design_pattern/behavioral/#behavioral","text":"Behavioral design patterns describe the communications between objects in a system.","title":"Behavioral"},{"location":"design_pattern/behavioral/observer/","text":"Observer The observer is publish-subscribe-pattern typically found in event-driven systems. The observable maintains a list of observers and notifies them on events like changes in state. sequenceDiagram participant Observable participant Observer1 participant Observer2 Observer1->>Observable: register Observer2->>Observable: register Note over Observable: Event occurs in Observable Observable->>Observer1: update(Event) Observable->>Observer2: update(Event) Weak reference In the case that the observable holds a strong reference to an observer, the observer would not be cleaned up by e.g garbage collection or reference counting if its life cycle ends. This can be solved by weak references.","title":"Observer"},{"location":"design_pattern/behavioral/observer/#observer","text":"The observer is publish-subscribe-pattern typically found in event-driven systems. The observable maintains a list of observers and notifies them on events like changes in state. sequenceDiagram participant Observable participant Observer1 participant Observer2 Observer1->>Observable: register Observer2->>Observable: register Note over Observable: Event occurs in Observable Observable->>Observer1: update(Event) Observable->>Observer2: update(Event)","title":"Observer"},{"location":"design_pattern/behavioral/observer/#weak-reference","text":"In the case that the observable holds a strong reference to an observer, the observer would not be cleaned up by e.g garbage collection or reference counting if its life cycle ends. This can be solved by weak references.","title":"Weak reference"},{"location":"design_pattern/behavioral/visitor/","text":"Visitor The visitor pattern separates algorithms from the object structures they work on. If supported, this can be done by double dispatch or reflection. Java In Java this can be done with the following interfaces including return value and exception propagation: public interface Visitor < R , E extends Throwable > { R visit ( ConcreteNode1 node ) throws E ; R visit ( ConcreteNode2 node ) throws E ; ... } public interface Node { < R , E extends Throwable > R accept ( Visitor < R , E > visitor ) throws E ; } //Example of concrete implementation public class ConcreteNode1 implements Node { public < R , E extends Throwable > R accept ( Visitor < R , E > visitor ) throws E { return visitor . visit ( this ); } ... } The implementation for a concrete node looks always the same and allows passing Void for R if no returned value is needed.","title":"Visitor"},{"location":"design_pattern/behavioral/visitor/#visitor","text":"The visitor pattern separates algorithms from the object structures they work on. If supported, this can be done by double dispatch or reflection.","title":"Visitor"},{"location":"design_pattern/behavioral/visitor/#java","text":"In Java this can be done with the following interfaces including return value and exception propagation: public interface Visitor < R , E extends Throwable > { R visit ( ConcreteNode1 node ) throws E ; R visit ( ConcreteNode2 node ) throws E ; ... } public interface Node { < R , E extends Throwable > R accept ( Visitor < R , E > visitor ) throws E ; } //Example of concrete implementation public class ConcreteNode1 implements Node { public < R , E extends Throwable > R accept ( Visitor < R , E > visitor ) throws E { return visitor . visit ( this ); } ... } The implementation for a concrete node looks always the same and allows passing Void for R if no returned value is needed.","title":"Java"},{"location":"infrastructure/","text":"Infrastructure This note is about infrastructure.","title":"Infrastructure"},{"location":"infrastructure/#infrastructure","text":"This note is about infrastructure.","title":"Infrastructure"},{"location":"infrastructure/docker/","text":"Docker This note is about Docker. Security For security reasons, a process in a docker container should run as a non-root user.","title":"Docker"},{"location":"infrastructure/docker/#docker","text":"This note is about Docker.","title":"Docker"},{"location":"infrastructure/docker/#security","text":"For security reasons, a process in a docker container should run as a non-root user.","title":"Security"},{"location":"machine_learning/","text":"Machine learning This note is about machine learning.","title":"Machine learning"},{"location":"machine_learning/#machine-learning","text":"This note is about machine learning.","title":"Machine learning"},{"location":"machine_learning/activation_functions/","text":"Activation functions Sigmoid / Logistic The Sigmoid activation function is defined by \\[ \\sigma(x) = \\frac{1}{1 + e^{-x}} \\] As the Sigmoid function has the bounds [0, 1], it is suited for multi-label classification as the element results can be trained as probabilities for a certain label to be true or not. Softmax The Softmax activation function is defined by \\[ \\sigma_j(x) = \\frac{e^{x_j}}{\\sum_j{e^{x_j}}} \\] In comparison to most activation functions, the sum of all element-wise results is constrained, precisely speaking: \\[ \\sum_j \\sigma_j(x) = 1 \\] Therefore the Softmax function is suited for multi-class classification as the element results can be trained as probabilities for a certain class in one category to be true or not.","title":"Activation functions"},{"location":"machine_learning/activation_functions/#activation-functions","text":"","title":"Activation functions"},{"location":"machine_learning/activation_functions/#sigmoid-logistic","text":"The Sigmoid activation function is defined by \\[ \\sigma(x) = \\frac{1}{1 + e^{-x}} \\] As the Sigmoid function has the bounds [0, 1], it is suited for multi-label classification as the element results can be trained as probabilities for a certain label to be true or not.","title":"Sigmoid / Logistic"},{"location":"machine_learning/activation_functions/#softmax","text":"The Softmax activation function is defined by \\[ \\sigma_j(x) = \\frac{e^{x_j}}{\\sum_j{e^{x_j}}} \\] In comparison to most activation functions, the sum of all element-wise results is constrained, precisely speaking: \\[ \\sum_j \\sigma_j(x) = 1 \\] Therefore the Softmax function is suited for multi-class classification as the element results can be trained as probabilities for a certain class in one category to be true or not.","title":"Softmax"},{"location":"machine_learning/data_preprocessing/","text":"Data preprocessing Label encoder Python: from sklearn.preprocessing import LabelEncoder One hot encoder Python: from sklearn.preprocessing import OneHotEncoder Column transformer Scikit-learn contains a class for applying multiple transformations to a dataset including dropping columns: Python: from sklearn.compose import ColumnTransformer Note: Does currently not work with a LabelEncoder. Image data Python: from keras.preprocessing.image import ImageDataGenerator","title":"Data preprocessing"},{"location":"machine_learning/data_preprocessing/#data-preprocessing","text":"","title":"Data preprocessing"},{"location":"machine_learning/data_preprocessing/#label-encoder","text":"Python: from sklearn.preprocessing import LabelEncoder","title":"Label encoder"},{"location":"machine_learning/data_preprocessing/#one-hot-encoder","text":"Python: from sklearn.preprocessing import OneHotEncoder","title":"One hot encoder"},{"location":"machine_learning/data_preprocessing/#column-transformer","text":"Scikit-learn contains a class for applying multiple transformations to a dataset including dropping columns: Python: from sklearn.compose import ColumnTransformer Note: Does currently not work with a LabelEncoder.","title":"Column transformer"},{"location":"machine_learning/data_preprocessing/#image-data","text":"Python: from keras.preprocessing.image import ImageDataGenerator","title":"Image data"},{"location":"machine_learning/feature_scaling/","text":"Feature scaling Feature scaling is a data preprocessing step to ease training of neural networks by reducing the numeric scale of different features to a uniform scale. Standardisation Standardisation transforms the feature distribution of data to zero mean and unit variance: \\[ z = \\frac{x - \\operatorname{mean}(x)}{\\operatorname{std}(x)} \\] Python: from sklearn.preprocessing import StandardScaler Normalisation Normalisation transforms the feature distribution to the interval \\([0,1]\\) : \\[ z = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} \\] Python: from sklearn.preprocessing import MinMaxScaler","title":"Feature scaling"},{"location":"machine_learning/feature_scaling/#feature-scaling","text":"Feature scaling is a data preprocessing step to ease training of neural networks by reducing the numeric scale of different features to a uniform scale.","title":"Feature scaling"},{"location":"machine_learning/feature_scaling/#standardisation","text":"Standardisation transforms the feature distribution of data to zero mean and unit variance: \\[ z = \\frac{x - \\operatorname{mean}(x)}{\\operatorname{std}(x)} \\] Python: from sklearn.preprocessing import StandardScaler","title":"Standardisation"},{"location":"machine_learning/feature_scaling/#normalisation","text":"Normalisation transforms the feature distribution to the interval \\([0,1]\\) : \\[ z = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} \\] Python: from sklearn.preprocessing import MinMaxScaler","title":"Normalisation"},{"location":"machine_learning/loss_functions/","text":"Loss functions This note is about loss functions used in training neural networks. Extensions The folowing extension can be added to induce effects in minimizing the loss function. Regularization Regularization penalizes high values of the parameters in a neural network and helps against overfitting. The corresponding loss extension term has the form \\[ L_p(\\Theta) = \\lambda \\|\\Theta\\|^p \\] with \\( \\lambda \\) the regularization factor, \\( \\Theta \\) the training parameters and \\( p \\in \\mathbb{N} \\) , typically with \\( p = 2 \\) (L2-Norm). Momentum To mitigate oscillations in the training of the parameters, a momentum extension can be used. This term is added to the update of the parameters in gradient descent \\[ \\Theta^{(t+1)} = \\Theta^{(t)} + \\Delta \\Theta_{GD}^{(t)} + \\nu \\Delta \\Theta^{(t-1)} = \\Theta^{(t)} + \\Delta \\Theta^{(t)} \\] with \\( t \\) the update step, \\( \\Theta \\) the training parameters and \\( \\nu \\) the momentum factor. Cross entropy For classification problems the output of the network can be choosen to be a vector of probabilities \\( q(y) \\) for the different classes \\( y \\in Y \\) . With the expected result \\( p(y) = \\delta_{y,\\hat{y}} \\) and the correct class \\( \\hat{y} \\) , the cross entropy can be used: \\[ H(p, q) = - \\sum_{y \\in Y}{p(y) \\log(q(y))} \\]","title":"Loss functions"},{"location":"machine_learning/loss_functions/#loss-functions","text":"This note is about loss functions used in training neural networks.","title":"Loss functions"},{"location":"machine_learning/loss_functions/#extensions","text":"The folowing extension can be added to induce effects in minimizing the loss function.","title":"Extensions"},{"location":"machine_learning/loss_functions/#regularization","text":"Regularization penalizes high values of the parameters in a neural network and helps against overfitting. The corresponding loss extension term has the form \\[ L_p(\\Theta) = \\lambda \\|\\Theta\\|^p \\] with \\( \\lambda \\) the regularization factor, \\( \\Theta \\) the training parameters and \\( p \\in \\mathbb{N} \\) , typically with \\( p = 2 \\) (L2-Norm).","title":"Regularization"},{"location":"machine_learning/loss_functions/#momentum","text":"To mitigate oscillations in the training of the parameters, a momentum extension can be used. This term is added to the update of the parameters in gradient descent \\[ \\Theta^{(t+1)} = \\Theta^{(t)} + \\Delta \\Theta_{GD}^{(t)} + \\nu \\Delta \\Theta^{(t-1)} = \\Theta^{(t)} + \\Delta \\Theta^{(t)} \\] with \\( t \\) the update step, \\( \\Theta \\) the training parameters and \\( \\nu \\) the momentum factor.","title":"Momentum"},{"location":"machine_learning/loss_functions/#cross-entropy","text":"For classification problems the output of the network can be choosen to be a vector of probabilities \\( q(y) \\) for the different classes \\( y \\in Y \\) . With the expected result \\( p(y) = \\delta_{y,\\hat{y}} \\) and the correct class \\( \\hat{y} \\) , the cross entropy can be used: \\[ H(p, q) = - \\sum_{y \\in Y}{p(y) \\log(q(y))} \\]","title":"Cross entropy"},{"location":"machine_learning/artifical_neural_networks/","text":"Artificial neural networks This note is about artificial neural networks (ANN). These networks belong to supervised learning and are used in the analysis and prediction of classification and regression problems.","title":"Artifical neural networks"},{"location":"machine_learning/artifical_neural_networks/#artificial-neural-networks","text":"This note is about artificial neural networks (ANN). These networks belong to supervised learning and are used in the analysis and prediction of classification and regression problems.","title":"Artificial neural networks"},{"location":"machine_learning/convolutional_neural_networks/","text":"Convolutional neural networks This note is about convolutional neural networks (CNN). These networks belong to supervised learning and are used in the field of computer vision.","title":"Convolutional neural networks"},{"location":"machine_learning/convolutional_neural_networks/#convolutional-neural-networks","text":"This note is about convolutional neural networks (CNN). These networks belong to supervised learning and are used in the field of computer vision.","title":"Convolutional neural networks"},{"location":"machine_learning/recurrent_neural_networks/","text":"Recurrent neural networks This note is about recurrent neural networks (RNN). These networks belong to supervised learning and are used in the analysis and prediction of time series or series like data. There are three general types of RNNs describing the series relation in input and output: Type Example One to many Sentence describing image Many to one Sentiment analysis Many to many Sentence translation Vanishing / exploding gradient problem RNNs can inhibit the vanishing / exploding gradient problem. One popular solution ist the use of long short-term memory (LSTM) nodes. Further readings: Diplomarbeit Josef Hochreiter, 1991: http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf","title":"Recurrent neural networks"},{"location":"machine_learning/recurrent_neural_networks/#recurrent-neural-networks","text":"This note is about recurrent neural networks (RNN). These networks belong to supervised learning and are used in the analysis and prediction of time series or series like data. There are three general types of RNNs describing the series relation in input and output: Type Example One to many Sentence describing image Many to one Sentiment analysis Many to many Sentence translation","title":"Recurrent neural networks"},{"location":"machine_learning/recurrent_neural_networks/#vanishing-exploding-gradient-problem","text":"RNNs can inhibit the vanishing / exploding gradient problem. One popular solution ist the use of long short-term memory (LSTM) nodes.","title":"Vanishing / exploding gradient problem"},{"location":"machine_learning/recurrent_neural_networks/#further-readings","text":"Diplomarbeit Josef Hochreiter, 1991: http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf","title":"Further readings:"},{"location":"machine_learning/recurrent_neural_networks/lstm/","text":"Long short-term memory An LSTM is a RNN without the vanishing gradient problem. It introduces a cell state for. It is defined by \\[\\begin{eqnarray} f_t & = & \\sigma(W_f \\cdot x_t + U_f \\cdot h_{t-1} + b_f) \\\\ i_t & = & \\sigma(W_i \\cdot x_t + U_i \\cdot h_{t-1} + b_i) \\\\ o_t & = & \\sigma(W_o \\cdot x_t + U_o \\cdot h_{t-1} + b_o) \\\\ \\tilde{c}_t & = & \\tanh(W_c \\cdot x_t + U_c \\cdot h_{t-1} + b_c) \\\\ c_t & = & f_i \\circ c_t + i_i \\circ \\tilde{c}_t \\\\ h_t & = & o_t \\circ \\tanh(c_t) \\end{eqnarray}\\] There exists different flavors of the LSTM, e.g. peephole LSTM or LSTM without a forget gate.","title":"Long short-term memory"},{"location":"machine_learning/recurrent_neural_networks/lstm/#long-short-term-memory","text":"An LSTM is a RNN without the vanishing gradient problem. It introduces a cell state for. It is defined by \\[\\begin{eqnarray} f_t & = & \\sigma(W_f \\cdot x_t + U_f \\cdot h_{t-1} + b_f) \\\\ i_t & = & \\sigma(W_i \\cdot x_t + U_i \\cdot h_{t-1} + b_i) \\\\ o_t & = & \\sigma(W_o \\cdot x_t + U_o \\cdot h_{t-1} + b_o) \\\\ \\tilde{c}_t & = & \\tanh(W_c \\cdot x_t + U_c \\cdot h_{t-1} + b_c) \\\\ c_t & = & f_i \\circ c_t + i_i \\circ \\tilde{c}_t \\\\ h_t & = & o_t \\circ \\tanh(c_t) \\end{eqnarray}\\] There exists different flavors of the LSTM, e.g. peephole LSTM or LSTM without a forget gate.","title":"Long short-term memory"},{"location":"machine_learning/reinforcement_learning/","text":"Reinforcement learning This note is about reinforcement learning (RL). sequenceDiagram participant Agent participant Environment Agent->>Environment: Action Environment->>Agent: State Environment->>Agent: Reward","title":"Reinforcement learning"},{"location":"machine_learning/reinforcement_learning/#reinforcement-learning","text":"This note is about reinforcement learning (RL). sequenceDiagram participant Agent participant Environment Agent->>Environment: Action Environment->>Agent: State Environment->>Agent: Reward","title":"Reinforcement learning"},{"location":"microservices/","text":"Microservices","title":"Microservices"},{"location":"microservices/#microservices","text":"","title":"Microservices"},{"location":"microservices/service_interaction/","text":"Service interaction This note describes interaction procedures used in microservice architectures. Choreography In the choreography each service knows its role in a business process and therefore it needs to know all following services it has to call for the business process. sequenceDiagram participant Service1 participant Service2 participant Service3 Service1->>Service2: request Service1->>Service3: request Service3->>Service2: request Note : Response side suppressed for clarity. Orchestration In the orchestration a business process is executed by a central coordinator. The services theirself do not have to know the underlying business process and services involved in the business process. sequenceDiagram participant Coordinator participant Service1 participant Service2 participant Service3 Coordinator->>Service1: request Coordinator->>Service2: request Coordinator->>Service3: request Coordinator->>Service2: request Note : Response side suppressed for clarity. Another definition Choreography = Event-driven communication Orchestration = Command-driven communication","title":"Service interaction"},{"location":"microservices/service_interaction/#service-interaction","text":"This note describes interaction procedures used in microservice architectures.","title":"Service interaction"},{"location":"microservices/service_interaction/#choreography","text":"In the choreography each service knows its role in a business process and therefore it needs to know all following services it has to call for the business process. sequenceDiagram participant Service1 participant Service2 participant Service3 Service1->>Service2: request Service1->>Service3: request Service3->>Service2: request Note : Response side suppressed for clarity.","title":"Choreography"},{"location":"microservices/service_interaction/#orchestration","text":"In the orchestration a business process is executed by a central coordinator. The services theirself do not have to know the underlying business process and services involved in the business process. sequenceDiagram participant Coordinator participant Service1 participant Service2 participant Service3 Coordinator->>Service1: request Coordinator->>Service2: request Coordinator->>Service3: request Coordinator->>Service2: request Note : Response side suppressed for clarity.","title":"Orchestration"},{"location":"microservices/service_interaction/#another-definition","text":"Choreography = Event-driven communication Orchestration = Command-driven communication","title":"Another definition"},{"location":"programming_languages/","text":"Programming languages This note is about programming languages.","title":"Programming languages"},{"location":"programming_languages/#programming-languages","text":"This note is about programming languages.","title":"Programming languages"},{"location":"programming_languages/c/","text":"C GCC The following command lists the activated optimizations gcc -Q <used optimizations, like -O2> --help-optimizers To enable or disable optimizations at code level, GCC specific pragmas can be used #pragma GCC push_options #pragma GCC optimize(\"O0\") <code> #pragma GCC pop_options","title":"C"},{"location":"programming_languages/c/#c","text":"","title":"C"},{"location":"programming_languages/c/#gcc","text":"The following command lists the activated optimizations gcc -Q <used optimizations, like -O2> --help-optimizers To enable or disable optimizations at code level, GCC specific pragmas can be used #pragma GCC push_options #pragma GCC optimize(\"O0\") <code> #pragma GCC pop_options","title":"GCC"},{"location":"programming_languages/go/","text":"Go This note is about the Go language. Design patterns Singleton type Singleton interface { DoSomething () } type singleton struct { } ( m * singleton ) DoSomething () { //Implementation } var instance * singleton var once sync . Once func GetInstance () Singleton { once . Do ( func () { instance = & singleton {} }) return * instance }","title":"Go"},{"location":"programming_languages/go/#go","text":"This note is about the Go language.","title":"Go"},{"location":"programming_languages/go/#design-patterns","text":"","title":"Design patterns"},{"location":"programming_languages/go/#singleton","text":"type Singleton interface { DoSomething () } type singleton struct { } ( m * singleton ) DoSomething () { //Implementation } var instance * singleton var once sync . Once func GetInstance () Singleton { once . Do ( func () { instance = & singleton {} }) return * instance }","title":"Singleton"},{"location":"programming_languages/python/","text":"Python Poetry Poetry is a Python tool for package and dependency management. Configuration To create the virtual enviroments in the project and not in a global directory, the following command can be used: poetry config virtualenvs.in-project true Jupyter notebooks Jupyter notebooks can be configured by a file jupyter_notebook_config.py enabling e.g. pre-save hooks. Pre-save hook This pre-save hook deletes output and execution count making notebooks VCS friendly: def scrub_output_pre_save ( model , ** kwargs ): \"\"\"scrub output before saving notebooks\"\"\" # only run on notebooks if model [ 'type' ] != 'notebook' : return # only run on nbformat v4 if model [ 'content' ][ 'nbformat' ] != 4 : return model [ 'content' ][ 'metadata' ] . pop ( 'signature' , None ) for cell in model [ 'content' ][ 'cells' ]: if cell [ 'cell_type' ] != 'code' : continue cell [ 'outputs' ] = [] cell [ 'execution_count' ] = None c . FileContentsManager . pre_save_hook = scrub_output_pre_save References https://github.com/ipython/ipython/pull/6896#issue-48344492","title":"Python"},{"location":"programming_languages/python/#python","text":"","title":"Python"},{"location":"programming_languages/python/#poetry","text":"Poetry is a Python tool for package and dependency management.","title":"Poetry"},{"location":"programming_languages/python/#configuration","text":"To create the virtual enviroments in the project and not in a global directory, the following command can be used: poetry config virtualenvs.in-project true","title":"Configuration"},{"location":"programming_languages/python/#jupyter-notebooks","text":"Jupyter notebooks can be configured by a file jupyter_notebook_config.py enabling e.g. pre-save hooks.","title":"Jupyter notebooks"},{"location":"programming_languages/python/#pre-save-hook","text":"This pre-save hook deletes output and execution count making notebooks VCS friendly: def scrub_output_pre_save ( model , ** kwargs ): \"\"\"scrub output before saving notebooks\"\"\" # only run on notebooks if model [ 'type' ] != 'notebook' : return # only run on nbformat v4 if model [ 'content' ][ 'nbformat' ] != 4 : return model [ 'content' ][ 'metadata' ] . pop ( 'signature' , None ) for cell in model [ 'content' ][ 'cells' ]: if cell [ 'cell_type' ] != 'code' : continue cell [ 'outputs' ] = [] cell [ 'execution_count' ] = None c . FileContentsManager . pre_save_hook = scrub_output_pre_save","title":"Pre-save hook"},{"location":"programming_languages/python/#references","text":"https://github.com/ipython/ipython/pull/6896#issue-48344492","title":"References"},{"location":"testing/","text":"Testing This note is about testing. Consumer-driven contract Links https://cucumber.io https://pact.io","title":"Testing"},{"location":"testing/#testing","text":"This note is about testing.","title":"Testing"},{"location":"testing/#consumer-driven-contract","text":"","title":"Consumer-driven contract"},{"location":"testing/#links","text":"https://cucumber.io https://pact.io","title":"Links"},{"location":"tooling/","text":"Tooling This note is about useful tooling. dotfiles Add to .zshrc the alias alias dotcfg = \"git --git-dir= $HOME /.dotfiles/ --work-tree= $HOME \" Then execute the following commands: git init --bare $HOME /.dotfiles dotcfg config --local status.showUntrackedFiles no Setting the upstream, adding files, etc. work as usual except the command dotcfg is used. Loading .env in shell if [ -f .env ] ; then export $( echo $( cat .env | sed 's/#.*//g' | xargs ) | envsubst ) fi","title":"Tooling"},{"location":"tooling/#tooling","text":"This note is about useful tooling.","title":"Tooling"},{"location":"tooling/#dotfiles","text":"Add to .zshrc the alias alias dotcfg = \"git --git-dir= $HOME /.dotfiles/ --work-tree= $HOME \" Then execute the following commands: git init --bare $HOME /.dotfiles dotcfg config --local status.showUntrackedFiles no Setting the upstream, adding files, etc. work as usual except the command dotcfg is used.","title":"dotfiles"},{"location":"tooling/#loading-env-in-shell","text":"if [ -f .env ] ; then export $( echo $( cat .env | sed 's/#.*//g' | xargs ) | envsubst ) fi","title":"Loading .env in shell"}]}